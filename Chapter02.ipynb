{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch Step-by-Step: A Beginner's Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    import requests\n",
    "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open('config.py', 'wb').write(r.content)    \n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "from config import *\n",
    "config_chapter2()\n",
    "# This is needed to render the plots in this chapter\n",
    "from plots.chapter2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinking the Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs data generation - so we do not need to copy code here\n",
    "%run -i data_generation/simple_linear_regression.py\n",
    "\n",
    "# Runs the first two parts of the sequence: data preparation and model configuration\n",
    "%run -i data_preparation/v0.py\n",
    "%run -i model_configuration/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_training/v0.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Sets model to TRAIN mode\n",
    "    model.train()\n",
    "\n",
    "    # Step 1 - Computes our model's predicted output - forward pass\n",
    "    # No more manual prediction!\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-Order Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "def cube(x):\n",
    "    return x ** 3\n",
    "\n",
    "def fourth_power(x):\n",
    "    return x ** 4\n",
    "\n",
    "# and so on and so forth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_exponentiation(x, exponent):\n",
    "    return x ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_exponentiation(x):\n",
    "    return x ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exponent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/projects/PyTorchStepByStep/model_configuration/v0.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mskeleton_exponentiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/PyTorchStepByStep/model_configuration/v0.py\u001b[0m in \u001b[0;36mskeleton_exponentiation\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mskeleton_exponentiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mexponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'exponent' is not defined"
     ]
    }
   ],
   "source": [
    "skeleton_exponentiation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponentiation_builder(exponent):\n",
    "    def skeleton_exponentiation(x):\n",
    "        return x ** exponent\n",
    "\n",
    "    return skeleton_exponentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.exponentiation_builder.<locals>.skeleton_exponentiation(x)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_function = exponentiation_builder(2)\n",
    "\n",
    "returned_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_function(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "square = exponentiation_builder(2)\n",
    "cube = exponentiation_builder(3)\n",
    "fourth_power = exponentiation_builder(4)\n",
    "\n",
    "# and so on and so forth..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def perform_train_step(x, y):\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "        \n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "        loss.backward()\n",
    "        # Step 4 - Updates parameters using gradients and the learning rate\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return perform_train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v1.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.make_train_step.<locals>.perform_train_step(x, y)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v1.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # Performs one train step and returns the corresponding loss\n",
    "    loss = train_step(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.1196],\n",
       "         [0.1395],\n",
       "         [0.2809],\n",
       "         [0.1834],\n",
       "         [0.3585],\n",
       "         [0.5427],\n",
       "         [0.0885],\n",
       "         [0.9489],\n",
       "         [0.9699],\n",
       "         [0.7751],\n",
       "         [0.9696],\n",
       "         [0.7320],\n",
       "         [0.0055],\n",
       "         [0.7069],\n",
       "         [0.8155],\n",
       "         [0.5979]]), tensor([[1.3214],\n",
       "         [1.3051],\n",
       "         [1.5846],\n",
       "         [1.4637],\n",
       "         [1.7462],\n",
       "         [2.2161],\n",
       "         [1.0708],\n",
       "         [2.8903],\n",
       "         [2.9727],\n",
       "         [2.4936],\n",
       "         [2.8401],\n",
       "         [2.4732],\n",
       "         [1.0632],\n",
       "         [2.4388],\n",
       "         [2.6606],\n",
       "         [2.0407]])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v1.py\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# Builds Dataset\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Builds DataLoader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v2.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
    "        # therefore, we need to send those mini-batches to the\n",
    "        # device where the model \"lives\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Performs one train step and returns the corresponding loss \n",
    "        # for this mini-batch\n",
    "        mini_batch_loss = train_step(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    # Computes average loss over all mini-batches - that's the epoch loss\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    \n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9684]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch Inner Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(device, data_loader, step):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = step(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py\n",
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v3.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9687]], device='cuda:0')), ('0.bias', tensor([1.0236], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_step(model, loss_fn):\n",
    "    # Builds function that performs a step in the validation loop\n",
    "    def perform_val_step(x, y):\n",
    "        # Sets model to EVAL mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # There is no need to compute Steps 3 and 4, since we don't update parameters during evaluation\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_val_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v2.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v4.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # VALIDATION\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9419]], device='cuda:0')), ('0.bias', tensor([1.0244], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_losses(losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-236c4d01efb56c8c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-236c4d01efb56c8c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IS_BINDER:\n",
    "    display(TB_LINK)\n",
    "else:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/projects/PyTorchStepByStep/model_training/v4.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    856\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    857\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;31m# this is needed since Module.__call__ sets up some extra tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mmake_tuple\u001b[0;34m(example_inputs)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# done primarily so that weird iterables fail here and not pybind11 code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching a tuple of feature (sample_x) and label (sample_y)\n",
    "sample_x, sample_y = next(iter(train_loader))\n",
    "\n",
    "# Since our model was sent to device, we need to do the same with the data\n",
    "# Even here, both model and data need to be on the same device!\n",
    "writer.add_graph(model, sample_x.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars('loss', {'training': loss, 'validation': val_loss}, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)\n",
    "\n",
    "# Creates a Summary Writer to interface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "\n",
    "# Fetches a single mini-batch so we can use add_graph\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "writer.add_graph(model, x_sample.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v5.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # VALIDATION\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Records both losses for each epoch under the main tag \"loss\"\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                       tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
    "                       global_step=epoch)\n",
    "\n",
    "# Closes the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9448]], device='cuda:0')), ('0.bias', tensor([1.0295], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4351), started 0:00:10 ago. (Use '!kill 4351' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-96d144879bc13365\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-96d144879bc13365\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is just for convenience, so you don't have to scroll back up :-)\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'epoch': n_epochs,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': losses,\n",
    "              'val_loss': val_losses}\n",
    "\n",
    "torch.save(checkpoint, 'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')), ('0.bias', tensor([0.8300], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "saved_epoch = checkpoint['epoch']\n",
    "saved_losses = checkpoint['loss']\n",
    "saved_val_losses = checkpoint['val_loss']\n",
    "\n",
    "model.train() # always use TRAIN for resuming training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9448]], device='cuda:0')), ('0.bias', tensor([1.0295], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9448]], device='cuda:0')), ('0.bias', tensor([1.0295], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_resumed_losses(saved_epoch, saved_losses, saved_val_losses, n_epochs, losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying / Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9448]], device='cuda:0')), ('0.bias', tensor([1.0295], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4185],\n",
       "        [1.6908],\n",
       "        [2.1381]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs = torch.tensor([[.20], [.34], [.57]])\n",
    "\n",
    "model.eval() # always use EVAL for fully trained models!\n",
    "model(new_inputs.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)\n",
    "\n",
    "# Creates a Summary Writer to interface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "\n",
    "# Fetches a single mini-batch so we can use add_graph\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "writer.add_graph(model, x_sample.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_training/v5.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # VALIDATION\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Records both losses for each epoch under the main tag \"loss\"\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                       tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
    "                       global_step=epoch)\n",
    "\n",
    "# Closes the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9440]], device='cuda:0')), ('0.bias', tensor([1.0249], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weird plots in TensorBoard?\n",
    "\n",
    "Run this if you want to clean up a previous run and start fresh with TensorBoard :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree('./runs/simple_linear_regression/', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
